 loading configuration 
Data output will be save in  fit_SDE19-09-17-15-37-04
 optimizing rand_beta_objective using Nelder-Mead with 5 batches.
starting optimization
Evaluating using rand_beta_objective
/home/alhaddwt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py:287: OptimizeWarning: Unknown solver options: gtol
  return self.minimizer(self.func, x0, **self.kwargs)
   0    8.000000000000    1.000000000000   -4.5
   1    8.400000000000    1.000000000000   -4.0
   2    8.000000000000    1.050000000000   -4.9
   3    7.600000000000    1.050000000000   -4.0
   4    7.800000000000    1.037500000000   -4.5
   5    7.800000000000    1.087500000000   -3.9
   6    7.950000000000    1.021875000000   -4.4
   7    7.900000000000    1.043750000000   -4.7
   8    8.000000000000    1.025000000000   -4.3
   9    7.900000000000    1.068750000000   -4.5
  10    7.925000000000    1.057812500000   -4.9
  11    8.025000000000    1.064062500000   -3.8
  12    7.931250000000    1.048828125000   -4.5
  13    7.962500000000    1.053906250000   -4.0
  14    7.912500000000    1.050781250000   -4.9
  15    7.875000000000    1.054687500000   -5.5
  16    7.831250000000    1.055078125000   -5.2
  17    7.887500000000    1.061718750000   -4.1
  18    7.906250000000    1.053515625000   -3.6
  19    7.900000000000    1.056250000000   -4.2
  20    7.893750000000    1.052734375000   -5.0
  21    7.868750000000    1.051171875000   -4.5
  22    7.876562500000    1.052441406250   -4.8
  23    7.892187500000    1.054980468750   -4.4
  24    7.880468750000    1.053076171875   -5.2
  25    7.861718750000    1.055029296875   -4.3
  26    7.885742187500    1.053308105469   -3.6
  27    7.877734375000    1.053881835937   -4.1
  28    7.884375000000    1.053710937500   -5.0
  29    7.881640625000    1.054516601563   -5.1
  30    7.872265625000    1.055493164062   -4.0
  31    7.881347656250    1.054156494141   -3.6
  32    7.878320312500    1.054602050781   -4.1
  33    7.879687500000    1.054199218750   -4.1
  34    7.876367187500    1.054284667969   -4.0
  35    7.877832031250    1.054522705078   -4.1
  36    7.876855468750    1.054364013672   -4.0
  37    7.877587890625    1.054483032227   -4.9
  38    7.872900390625    1.054971313477   -4.1
  39    7.877990722656    1.054392242432   -3.7
  40    7.876293945313    1.054585266113   -3.9
  41    7.877343750000    1.054443359375   -4.8
  42    7.876049804688    1.054545593262   -4.4
  43    7.876110839844    1.054555511475   -4.7
  44    7.876232910156    1.054575347900   -4.7
  45    7.876202392578    1.054570388794   -5.0
  46    7.873858642578    1.054814529419   -3.6
  47    7.876472473145    1.054536151886   -5.2
  48    7.875270080566    1.054653263092   -3.8
  49    7.875969314575    1.054591107368   -4.7
  50    7.875736236572    1.054611825943   -5.0
  51    7.875601196289    1.054628944397   -5.3
  52    7.874864959717    1.054704618454   -4.0
  53    7.875518417358    1.054635024071   -4.1
  54    7.875300598145    1.054658222198   -4.7
  55    7.875368118286    1.054649662971   -4.7
  56    7.875067520142    1.054678940773   -4.1
  57    7.875242328644    1.054663401842   -4.7
  58    7.875125789642    1.054673761129   -4.8
  59    7.874757671356    1.054711598158   -4.4
  60    7.875215506554    1.054665146768   -3.8
  61    7.875062894821    1.054680630565   -4.2
  62    7.875184059143    1.054668581486   -4.7
  63    7.875121164322    1.054675450921   -4.3
  64    7.875106596947    1.054676745832   -4.2
  65    7.875092029572    1.054678040743   -3.5
  66    7.875031447411    1.054684065282   -3.9
  67    7.874939417839    1.054693524539   -3.6
  68    7.874977570772    1.054689653590   -3.8
  69    7.875053876638    1.054681911692   -4.2
  70    7.875022429228    1.054685346410   -3.5
  71    7.875029192865    1.054684385564   -4.0
  72    7.875024683774    1.054685026128   -4.3
  73    7.874970807135    1.054690614436   -5.1
  74    7.874946123362    1.054693088308   -3.5
  75    7.875005043671    1.054687041673   -3.8
  76    7.874985403568    1.054689057218   -4.0
  77    7.875012341887    1.054686263064   -3.9
  78    8.272296303154    1.534864941512   -4.1
  79    8.685911118312    1.534864941512   -4.3
  80    8.272296303154    1.611608188587   -3.5
  81    8.685911118312    1.458121694436   -4.2
  82    9.099525933469    1.458121694436   -3.3
  83    8.479103710733    1.515679129743   -3.4
  84    8.685911118312    1.496493317974   -3.7
  85    8.479103710733    1.534864941512   -3.5
  86    8.892718525890    1.496493317974   -3.3
  87    8.582507414522    1.525272035627   -3.4
  88    8.685911118312    1.515679129743   -2.9
  89    8.582507414522    1.534864941512   -3.8
  90    8.582507414522    1.554050753281   -3.2
  91    8.608358340469    1.544457847396   -3.2
  92    8.634209266417    1.534864941512   -4.1
  93    8.685911118312    1.525272035627   -4.9
  94    8.737612970206    1.525272035627   -3.9
  95    8.660060192364    1.532466715041   -4.2
  96    8.711762044259    1.527670262098   -4.2
  97    8.672985655338    1.531267601805   -3.6
  98    8.685911118312    1.530068488570   -3.8
  99    8.672985655338    1.528869375334   -3.7
 100    8.698836581285    1.526471148863   -4.6
 101    8.698836581285    1.521674695921   -4.2
 102    8.695605215542    1.523773144083   -3.1
 103    8.692373849798    1.525871592245   -5.0
 104    8.685911118312    1.527670262098   -3.5
 105    8.692373849798    1.523473365774   -3.5
 106    8.687526801183    1.526621038017   -3.1
 107    8.689142484055    1.525571813936   -4.1
 108    8.689142484055    1.526770927172   -3.8
 109    8.692373849798    1.524672479009   -4.2
 110    8.695605215542    1.524972257318   -3.7
 111    8.690758166927    1.525421924782   -3.8
 112    8.692373849798    1.525272035627   -4.2
 113    8.690758166927    1.525721703091   -3.7
 114    8.693989532670    1.525421924782   -3.7
 115    8.693181691234    1.525496869359   -4.7
 116    8.693181691234    1.526096425977   -3.1
 117    8.692575810157    1.525478133215   -3.9
 118    8.692777770516    1.525684230802   -5.0
 119    8.692373849798    1.525571813936   -4.2
 120    8.692777770516    1.525984009111   -4.2
 121    8.692676790337    1.525880960317   -4.7
 122    8.692474829978    1.525674862730   -4.2
 123    8.692626300247    1.525829435920   -3.8
 124    8.692575810157    1.525777911524   -4.2
 125    8.692727280427    1.525782595560   -3.4
 126    8.692626300247    1.525679546766   -3.3
 127    8.692702035382    1.525756833361   -3.6
 128    8.692651545292    1.525705308964   -4.5
 129    8.692853505651    1.525611628243   -4.3
 130    8.692784081778    1.525653199063   -3.3
 131    8.692714657904    1.525694769883   -4.0
 132    8.692676790337    1.525731071163   -5.0
 133    8.692739902949    1.525720532082   -4.7
 134    8.692733591688    1.525714091532   -3.6
 135    8.692727280427    1.525707650982   -3.8
 136    8.692695724120    1.525712920523   -4.0
 137    8.692645234031    1.525736340703   -4.4
 138    8.692626300247    1.525754491343   -3.4
 139    8.692678368152    1.525723313228   -3.7
 140    8.692661012184    1.525733705933   -3.5
 141    8.692686257229    1.525721995843   -3.4
 142    8.692651545292    1.525742781253   -3.4
 143    8.692677579244    1.525727192195   -3.7
 144    8.692693357398    1.525724557425   -4.3
 145    8.692692568490    1.525728436392   -3.6
 146    8.692681326556    1.525727503245   -4.4
 147    8.692664759495    1.525734016982   -3.1
 148    8.692686207922    1.525726922314   -4.9
 149    8.692681671703    1.525730490233   -4.4
 150    8.692681412843    1.525728249992   -3.5
 151    8.692681499129    1.525728996739   -3.3
 152    8.692679058446    1.525729287204   -3.4
 153    8.692674349654    1.525731361628   -4.8
 154    8.692672081544    1.525733145587   -4.0
 155    8.692673825770    1.525732180991   -3.5
 156    8.692675569995    1.525731216395   -3.6
 157    8.692677924392    1.525730179183   -3.9
 158    8.692679144733    1.525730033951   -4.8
/home/alhaddwt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_basinhopping.py:679: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  if isinstance(callback, collections.Callable):
rand_beta_objective
[7.875     1.0546875]
Traceback (most recent call last):
  File "fit_model.py", line 92, in <module>
    width,height,angle, eig_vect_opt,Hess = this_model.compute_ellipse(inference='rand_beta_objective', param=optim.x, batch_size=current_batch_size , plot=False);
TypeError: compute_ellipse() got multiple values for argument 'inference'
sys:1: ResourceWarning: unclosed file <_io.TextIOWrapper name='beta_config_test.JSON' mode='r' encoding='UTF-8'>
sys:1: ResourceWarning: unclosed file <_io.TextIOWrapper name='fit_SDE19-09-17-15-37-04/results.out' mode='w' encoding='UTF-8'>
